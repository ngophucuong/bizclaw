# âš¡ BizClaw

> **Háº¡ táº§ng AI Agent nhanh, module hoÃ¡ â€” viáº¿t hoÃ n toÃ n báº±ng Rust.**

BizClaw lÃ  ná»n táº£ng AI Agent kiáº¿n trÃºc trait-driven, cÃ³ thá»ƒ cháº¡y **má»i nÆ¡i** â€” tá»« Raspberry Pi Ä‘áº¿n cloud server. Há»— trá»£ nhiá»u LLM provider, kÃªnh giao tiáº¿p, vÃ  cÃ´ng cá»¥ thÃ´ng qua kiáº¿n trÃºc thá»‘ng nháº¥t, hoÃ¡n Ä‘á»•i Ä‘Æ°á»£c.

[![Rust](https://img.shields.io/badge/Rust-100%25-orange?logo=rust)](https://www.rust-lang.org/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/tests-66%20passing-brightgreen)]()
[![Crates](https://img.shields.io/badge/crates-12%2F12-success)]()

---

## ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t

### ğŸš€ 100% Tá»± Host â€” KhÃ´ng phá»¥ thuá»™c Cloud

- **100% Äá»™c láº­p:** Clone vá» lÃ  cháº¡y â€” laptop, VPS, hay Raspberry Pi. KhÃ´ng token khoÃ¡, khÃ´ng telemetry.
- **Dá»¯ liá»‡u ná»™i bá»™:** Chat history, API Keys mÃ£ hoÃ¡ AES-256 lÆ°u local.
- **Offline AI:** Brain Engine cháº¡y LLM offline (Llama, DeepSeek) â€” tá»‘i Æ°u cho 512MB RAM.

### ğŸ¯ TÃ­nh nÄƒng

| Háº¡ng má»¥c | Chi tiáº¿t |
|----------|----------|
| **ğŸ§  Brain Engine** | LLaMA inference: GGUF, mmap, quantization, Flash Attention, FP16 KV Cache |
| **ğŸ”Œ 8 Providers** | OpenAI, Anthropic, Ollama, llama.cpp, Brain, Gemini, DeepSeek, Groq |
| **ğŸ’¬ 6 Channels** | CLI, Zalo Personal, Telegram, Discord (Gateway WS), Email (IMAP/SMTP), Webhook |
| **ğŸ¢ Multi-Tenant** | Admin Platform, JWT Auth, Tenant Manager, Pairing Codes, Audit Log |
| **ğŸŒ Web Dashboard** | Chat UI (VI/EN), WebSocket real-time, embedded SPA |
| **ğŸ› ï¸ 5 Tools** | Shell, File, Web Search, Group Summarizer, Google Calendar |
| **ğŸ”’ Security** | Command allowlist, AES-256, HMAC-SHA256, JWT + bcrypt |
| **ğŸ’¾ Memory** | SQLite + RAG-style retrieval, keyword search, relevance scoring |
| **âš¡ SIMD** | ARM NEON, x86 SSE2/AVX2 auto-dispatch |

### ğŸ—ï¸ Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 bizclaw (CLI)                     â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚          â”‚  bizclaw-agent   â”‚ â† RAG Memory        â”‚
â”‚          â”‚  Multi-round     â”‚   + Tool Calling     â”‚
â”‚          â”‚  Tool Calling    â”‚   (max 3 rounds)     â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚    â–¼            â–¼             â–¼                   â”‚
â”‚ Providers    Channels       Tools                 â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€                 â”‚
â”‚ OpenAI      CLI            Shell                 â”‚
â”‚ Anthropic   Zalo           File                  â”‚
â”‚ Ollama      Telegram       Web Search            â”‚
â”‚ Gemini      Discord        Calendar              â”‚
â”‚ DeepSeek    Email          Group Summarizer       â”‚
â”‚ Groq        Webhook                              â”‚
â”‚ Brain                                            â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚    â–¼            â–¼             â–¼                   â”‚
â”‚ Memory       Security      Gateway               â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€                 â”‚
â”‚ SQLite      Allowlist      Axum HTTP             â”‚
â”‚ RAG         AES-256        WebSocket             â”‚
â”‚ Vector      Sandbox        REST API              â”‚
â”‚                                                   â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚          â”‚  bizclaw-brain   â”‚                     â”‚
â”‚          â”‚  GGUF + SIMD     â”‚                     â”‚
â”‚          â”‚  Offline LLM     â”‚                     â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸš€ Báº¯t Ä‘áº§u nhanh

```bash
# Clone vÃ  build
git clone https://github.com/nguyenduchoai/bizclaw.git
cd bizclaw
cargo build --release

# CÃ i Ä‘áº·t (wizard tÆ°Æ¡ng tÃ¡c)
./target/release/bizclaw init

# Chat ngay (interactive CLI)
./target/release/bizclaw agent --interactive

# Chat 1 cÃ¢u
./target/release/bizclaw agent -m "Xin chÃ o!"

# Má»Ÿ Web Dashboard (single tenant)
./target/release/bizclaw serve
```

### ğŸ¢ Cháº¿ Ä‘á»™ triá»ƒn khai

BizClaw há»— trá»£ **2 cháº¿ Ä‘á»™ cháº¡y**:

#### 1. Standalone Mode â€” Má»™t tenant duy nháº¥t

PhÃ¹ há»£p cho: cÃ¡ nhÃ¢n, startup nhá», test/demo.

```bash
# Chá»‰ cáº§n binary `bizclaw` â€” KHÃ”NG cáº§n bizclaw-platform
./target/release/bizclaw serve --port 3000

# Hoáº·c cháº¡y channels trá»±c tiáº¿p
./target/release/bizclaw channel start --all
```

- KhÃ´ng cáº§n Admin Platform
- Config báº±ng file `~/.bizclaw/config.toml`
- Web Dashboard táº¡i `localhost:3000`
- Quáº£n lÃ½ channels qua CLI hoáº·c dashboard

#### 2. Platform Mode â€” Multi-Tenant

PhÃ¹ há»£p cho: agency, nhiá»u bots, production server.

```bash
# Cáº§n build cáº£ 2 binaries
cargo build --release --bin bizclaw --bin bizclaw-platform

# Khá»Ÿi táº¡o admin user
./target/release/bizclaw-platform --init-admin

# Cháº¡y platform (quáº£n lÃ½ nhiá»u tenants)
./target/release/bizclaw-platform --port 3001

# Má»—i tenant sáº½ Ä‘Æ°á»£c táº¡o qua Admin Dashboard
# vÃ  tá»± Ä‘á»™ng cháº¡y trÃªn port riÃªng (10001, 10002, ...)
```

- Admin Dashboard táº¡i `http://localhost:3001`
- Má»—i tenant lÃ  1 process `bizclaw serve` riÃªng
- Tenant quáº£n lÃ½ qua REST API hoáº·c Web UI
- JWT Auth + Pairing Code cho báº£o máº­t

### ğŸ§  Ollama / Brain Engine â€” Shared Models

Ollama models Ä‘Æ°á»£c **dÃ¹ng chung** giá»¯a táº¥t cáº£ tenants:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Ollama Server (shared)           â”‚
â”‚         localhost:11434                   â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚         â”‚ tinyllama (1.5GB)â”‚             â”‚
â”‚         â”‚ llama3.2  (3.8GB)â”‚             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚              â–²    â–²    â–²                â”‚
â”‚              â”‚    â”‚    â”‚                â”‚
â”‚  Tenant A â”€â”€â”€â”˜    â”‚    â””â”€â”€â”€ Tenant C    â”‚
â”‚  (ollama/         â”‚         (openai/    â”‚
â”‚   tinyllama)      â”‚          gpt-4o)    â”‚
â”‚              Tenant B                    â”‚
â”‚              (ollama/                    â”‚
â”‚               llama3.2)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Pull model 1 láº§n** â†’ táº¥t cáº£ tenant dÃ¹ng Ä‘Æ°á»£c
- **RAM:** ~2-4GB cho 7B model (chá»‰ 1 model active cÃ¹ng lÃºc)
- **Má»—i tenant chá»n model riÃªng** trong config (provider + model)
- **Cloud fallback:** Náº¿u khÃ´ng Ä‘á»§ RAM â†’ dÃ¹ng OpenAI, Anthropic, Gemini

```bash
# CÃ i Ollama trÃªn server
curl -fsSL https://ollama.ai/install.sh | sh

# Pull model nháº¹ (~1.5GB)
ollama pull tinyllama

# Hoáº·c model máº¡nh hÆ¡n (~3.8GB, cáº§n 4GB+ RAM)
ollama pull llama3.2
```

### âš™ï¸ Cáº¥u hÃ¬nh

File config táº¡i `~/.bizclaw/config.toml`:

```toml
default_provider = "ollama"    # hoáº·c "openai", "anthropic", "gemini"
default_model = "tinyllama"
default_temperature = 0.7

[identity]
name = "BizClaw"
persona = "Trá»£ lÃ½ AI thÃ´ng minh"
system_prompt = "Báº¡n lÃ  BizClaw, trá»£ lÃ½ AI nhanh vÃ  cÃ³ nÄƒng lá»±c."

[brain]
enabled = false                # true = dÃ¹ng Brain Engine (offline)
model_path = "~/.bizclaw/models/tinyllama.gguf"

[memory]
backend = "sqlite"
auto_save = true

[gateway]
enabled = true
host = "127.0.0.1"
port = 3000

[autonomy]
level = "supervised"
allowed_commands = ["ls", "cat", "echo", "pwd", "find", "grep"]
```

### ğŸ“¦ Crate Map

| Crate | MÃ´ táº£ | Tráº¡ng thÃ¡i |
|-------|--------|------------|
| `bizclaw-core` | Traits, types, config, errors | âœ… |
| `bizclaw-brain` | GGUF inference + SIMD | âœ… |
| `bizclaw-providers` | 8 LLM providers | âœ… |
| `bizclaw-channels` | 6 channels (CLI, Zalo, TG, Discord, Email, Webhook) | âœ… |
| `bizclaw-memory` | SQLite + RAG retrieval | âœ… |
| `bizclaw-tools` | 5 tools (Shell, File, Search, Calendar, Summarizer) | âœ… |
| `bizclaw-security` | Allowlist, AES-256, Sandbox | âœ… |
| `bizclaw-agent` | Agent loop + multi-round tool calling | âœ… |
| `bizclaw-gateway` | Axum HTTP + WebSocket + Dashboard | âœ… |
| `bizclaw-runtime` | Native process adapter | âœ… |
| `bizclaw-platform` | Multi-tenant admin platform | âœ… |

### ğŸ”’ Báº£o máº­t

| TÃ­nh nÄƒng | MÃ´ táº£ |
|-----------|--------|
| **Allowlist** | Chá»‰ lá»‡nh Ä‘Æ°á»£c phÃ©p má»›i thá»±c thi |
| **Path Restrictions** | Cháº·n `~/.ssh`, `/etc` |
| **Sandbox** | Timeout, cáº¯t output |
| **AES-256** | MÃ£ hoÃ¡ key (hostname+user) |
| **JWT + bcrypt** | Admin Platform auth |
| **HMAC-SHA256** | Webhook signature |

### ğŸ“¡ Gateway API

| Endpoint | Method | MÃ´ táº£ |
|----------|--------|--------|
| `/health` | GET | Health check |
| `/api/v1/info` | GET | System info |
| `/api/v1/config` | GET | Config (sanitized) |
| `/api/v1/providers` | GET | Available providers |
| `/api/v1/channels` | GET | Channel list |
| `/ws` | WS | Real-time chat |

### ğŸ“ Project Structure

```
bizclaw/
â”œâ”€â”€ Cargo.toml                 # Workspace root
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs                # bizclaw CLI binary
â”‚   â””â”€â”€ platform_main.rs       # bizclaw-platform binary
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ bizclaw-core/          # Traits, types, config
â”‚   â”œâ”€â”€ bizclaw-brain/         # Local GGUF inference
â”‚   â”œâ”€â”€ bizclaw-providers/     # LLM providers (8)
â”‚   â”œâ”€â”€ bizclaw-channels/      # Communication (6 channels)
â”‚   â”œâ”€â”€ bizclaw-memory/        # SQLite + RAG
â”‚   â”œâ”€â”€ bizclaw-tools/         # Tools (5)
â”‚   â”œâ”€â”€ bizclaw-security/      # AES-256, Sandbox
â”‚   â”œâ”€â”€ bizclaw-agent/         # Agent engine
â”‚   â”œâ”€â”€ bizclaw-gateway/       # HTTP + WebSocket + Dashboard
â”‚   â”œâ”€â”€ bizclaw-runtime/       # Process adapters
â”‚   â””â”€â”€ bizclaw-platform/      # Multi-tenant admin
â””â”€â”€ deploy/                    # Deployment configs
```

### ğŸ§ª Testing

```bash
# Cháº¡y táº¥t cáº£ tests
cargo test --workspace

# Test tá»«ng crate
cargo test -p bizclaw-brain     # Brain engine (12 tests)
cargo test -p bizclaw-core      # Core types (11 tests)
cargo test -p bizclaw-tools     # Tools (5 tests)
cargo test -p bizclaw-agent     # Agent (4 tests)
cargo test -p bizclaw-gateway   # Gateway (4 tests)
```

### ğŸš€ Production Deployment

```bash
# 1. Build release binaries
cargo build --release

# 2a. Standalone (1 bot)
cp target/release/bizclaw /usr/local/bin/
bizclaw init
bizclaw serve --port 3000

# 2b. Platform (nhiá»u bots)
cp target/release/bizclaw target/release/bizclaw-platform /usr/local/bin/
bizclaw-platform --init-admin --port 3001

# 3. Systemd service
sudo tee /etc/systemd/system/bizclaw-platform.service << 'EOF'
[Unit]
Description=BizClaw Multi-Tenant Platform
After=network.target

[Service]
Type=simple
ExecStart=/usr/local/bin/bizclaw-platform --port 3001
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF
sudo systemctl enable --now bizclaw-platform

# 4. Nginx reverse proxy (optional)
# admin.yourdomain.com â†’ :3001
# bot1.yourdomain.com  â†’ :10001
```

### ğŸ“Š Stats

| Metric | Value |
|--------|-------|
| **Language** | 100% Rust |
| **Crates** | 12 (11 library + 1 binary) |
| **Lines of Code** | ~11,200 |
| **Tests** | 66 passing |
| **Providers** | 8 |
| **Channels** | 6 |
| **Tools** | 5 |
| **Binary Size** | bizclaw 7.6MB, bizclaw-platform 5.6MB |
| **RAM (idle)** | ~1.8MB |

---

## ğŸ‡¬ğŸ‡§ English

### Features

- **ğŸ§  Brain Engine** â€” Local LLaMA inference via GGUF with SIMD
- **ğŸ”Œ 8 Providers** â€” OpenAI, Anthropic, Ollama, llama.cpp, Brain, Gemini, DeepSeek, Groq
- **ğŸ’¬ 6 Channels** â€” CLI, Zalo, Telegram, Discord, Email (IMAP/SMTP), Webhook
- **ğŸ¢ Multi-Tenant Platform** â€” Admin dashboard, JWT auth, tenant lifecycle
- **ğŸŒ Web Dashboard** â€” Bilingual (VI/EN), real-time WebSocket chat
- **ğŸ› ï¸ 5 Tools** â€” Shell, File, Web Search, Group Summarizer, Calendar
- **ğŸ”’ Security** â€” AES-256, Command allowlists, sandbox, HMAC-SHA256
- **ğŸ’¾ RAG Memory** â€” SQLite with keyword search and relevance scoring
- **âš¡ SIMD** â€” ARM NEON, x86 SSE2/AVX2 auto-dispatch

### Quick Start

```bash
git clone https://github.com/nguyenduchoai/bizclaw.git
cd bizclaw && cargo build --release

# Standalone (single bot)
./target/release/bizclaw init
./target/release/bizclaw agent --interactive

# Platform (multi-tenant)
./target/release/bizclaw-platform --init-admin
./target/release/bizclaw-platform --port 3001
```

### Deployment Modes

| Mode | Binary | Use Case |
|------|--------|----------|
| **Standalone** | `bizclaw` only | Single bot, personal use, testing |
| **Platform** | `bizclaw` + `bizclaw-platform` | Multiple bots, agency, production |

### Ollama Shared Models

All tenants share the same Ollama instance. Pull a model once, every tenant can use it.

```bash
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull tinyllama    # ~1.5GB, good for 2GB RAM
ollama pull llama3.2     # ~3.8GB, needs 4GB+ RAM
```

Each tenant selects its own provider/model in config. Cloud providers (OpenAI, etc.) work without Ollama.

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

**BizClaw** â€” *AI nhanh, má»i nÆ¡i. / Fast AI, everywhere.*
